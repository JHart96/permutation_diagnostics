set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null_1 <- gbi_MCMC(associations, thin=1, samples=1000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
# plot_gbi_null_custom(gbi_null_1, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=1, samples=1000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null_1, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=10, samples=1000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null_1, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=100, samples=1000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null_1, ylim=c(0, 1))
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(1)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
# adj[1, 2] <- 0.75
# adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=1, samples=10000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=10, samples=10000, chains=4, burnin=1)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=10, samples=10000, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(1)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
adj[1, 2] <- 0.75
adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
beep(1)
beepr::beep(1)
install.packages("beepr")
beepr::beep(1)
beepr::beep(1)
beepr::beep(2)
beepr::beep(3)
beepr::beep(4)
beepr::beep(5)
beepr::beep(10)
beepr::beep(7)
beepr::beep(3)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=10, samples=20000, chains=10, burnin=1)
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC(associations, thin=10, samples=2000, chains=2, burnin=1)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=2, burnin=1)
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
beepr::beep(3)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=20000, chains=2, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=10, burnin=1)
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
source("~/Workspace/permutation_diagnostics/permutations.R")
source("~/Workspace/permutation_diagnostics/permutations.R")
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=20, chains=10, burnin=1)
source("~/Workspace/permutation_diagnostics/permutations.R")
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=20, chains=10, burnin=1)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=10, burnin=1)
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=20, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=200, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10, samples=2000, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(123)
# Bad example: thin = 1, samples = 10000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
cumsum(gbi_null$mcmc[[2]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[2]][,3]))
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
p_vals_chains
p_vals_chains[, 10]
p_vals_chains[, 11]
tail(p_vals_chains)
tail(p_vals_chains, 1000)
tail(p_vals_chains, 1000)[1, ]
tail(p_vals_chains, 1)[1, ]
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ])
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.05
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 5
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) > 0.01
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ])
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) > 0.01
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) > 0.001
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
p_vals_chains[, 11]
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) > 0.01
tail(p_vals_chains, 1)
tail(p_vals_chains, 1000)
p_vals_chains[-1, ]
tail(p_vals_chains, 1000)[1, ]
tail(p_vals_chains, 1000)
tail(p_vals_chains, 10)
tail(p_vals_chains, 1)[1, ]
tail(p_vals_chains, 1000)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
mean(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) > 0.01)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# What proportion o fp-values have changed by less than 0.01 in the last 1000 swaps
mean(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
mean(tail(p_vals_chains, 1)[1, ] < 0.05)
mean(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# What proportion of p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
mean(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# What proportion of p-values give the wrong conclusion?x
mean(tail(p_vals_chains, 1)[1, ] > 0.05)
mean(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
summary(gbi_null)
36/20000
100 * 36/20000
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# What proportion of p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
mean(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# What proportion of p-values give the wrong conclusion?
mean(tail(p_vals_chains, 1)[1, ] > 0.05)
# What proportion of stable p-values give the wrong conclusion?
mean(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
summary(gbi_null)["CV", "ESS"]
summary(gbi_null)["CV", "ESS"]
# Effective sample size as a proportion of total samples
summary(gbi_null)[1, ]
# Effective sample size as a proportion of total samples
gbi_null$mcmc[, 3]
plot(gbi_null$mcmc[, 3])
plot(gbi_null$mcmc[, 3], density=FALSE)
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=1000, samples=1000, chains=10, burnin=1000)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 36/20000
summary(gbi_null)
plot(gbi_null$mcmc[, 3], density=FALSE)
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 2000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=10000, samples=1000, chains=10, burnin=1000)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 36/20000
summary(gbi_null)
plot(gbi_null$mcmc[, 3], density=FALSE)
# Effective sample size as a proportion of total samples
100 * 36/20000
100 * 1430/2000
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 36/20000
100 * 1430/2000
set.seed(1)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
# adj[1, 2] <- 0.75
# adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000)
library(asnipe)
library(compiler)
library(mcmcse)
library(aninet)
source("permutations.R")
set.seed(1)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
# adj[1, 2] <- 0.75
# adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
set.seed(123)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
# adj[1, 2] <- 0.75
# adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000)
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null, ylim=c(0, 1))
plot(gbi_null$mcmc[, 3], density=FALSE)
summary(gbi_null)
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
# gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000) # Bad
gbi_null <- gbi_MCMC_custom(associations, thin=10000, samples=1000, chains=10, burnin=1000) # Good
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 36/20000
100 * 1430/2000
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] > 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
# gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000) # Bad
gbi_null_good <- gbi_MCMC_custom(associations, thin=10000, samples=1000, chains=10, burnin=1000) # Good
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
# gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000) # Bad
gbi_null_good <- gbi_MCMC_custom(associations, thin=10000, samples=1000, chains=10, burnin=1000) # Good
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null_good, ylim=c(0, 1))
summary(gbi_null)
summary(gbi_null_good)
plot(gbi_null$mcmc[, 3], density=FALSE)
plot(gbi_null$mcmc[, 3], density=FALSE)
plot(gbi_null_good$mcmc[, 3], density=FALSE)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
p_vals_chains
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null_good$mcmc[[i]][,3] > gbi_null_good$observed[3])/(1:length(gbi_null_good$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
# gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000) # Bad
gbi_null_good <- gbi_MCMC_custom(associations, thin=10000, samples=2000, chains=10, burnin=1000) # Good
# sapply(1:4, function(i) mean(gbi_null$mcmc[[i]][, 3] > gbi_null$observed[3]))
plot_gbi_null_custom(gbi_null_good, ylim=c(0, 1))
summary(gbi_null_good)
plot(gbi_null$mcmc[, 3], density=FALSE)
plot(gbi_null_good$mcmc[, 3], density=FALSE)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null_good$mcmc[[i]][,3] > gbi_null_good$observed[3])/(1:length(gbi_null_good$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null_good$mcmc[[i]][,3] > gbi_null_good$observed[3])/(1:length(gbi_null_good$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null_good$mcmc[[i]][,3] > gbi_null_good$observed[3])/(1:length(gbi_null_good$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
summary(gbi_null)
p_vals_chains <- sapply(1:10, function(i) cumsum(gbi_null$mcmc[[i]][,3] > gbi_null$observed[3])/(1:length(gbi_null$mcmc[[i]][,3])))
# How many p-values have changed by less than 0.01 in the last 1000 swaps (could be considered stable?)
sum(abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# How many p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05)
# How many "stable" p-values give the wrong conclusion?
sum(tail(p_vals_chains, 1)[1, ] < 0.05 & abs(tail(p_vals_chains, 1)[1, ] - tail(p_vals_chains, 1000)[1, ]) < 0.01)
# Effective sample size as a proportion of total samples
100 * 23/19000
100 * 1430/2000
tail(p_vals_chains, 1)
vignette("getting_started", "bisonR")
vignette(all=FALSE)
vignette(bisonR)
library(bisonR)
vignette(all=FALSE)
vignette(all=FALSE)
Sys.getenv("HOME")
library(asnipe)
library(compiler)
library(mcmcse)
library(aninet)
source("permutations.R")
set.seed(123)
num_individuals <- 100
num_observations <- 500
# adj <- matrix(rnorm(num_individuals^2, sd=0.1), num_individuals, num_individuals)
# adj <- adj %*% t(adj)
adj <- diag(1, num_individuals)
# adj[1, 2] <- 0.75
# adj[2, 1] <- 0.75
associations <- round(plogis(MASS::mvrnorm(num_observations, rep(-0.5, num_individuals), adj)))
associations
set.seed(123)
# Bad example: thin = 1, samples = 20000, burnin = 0
# Good example: thin = 10000, samples = 1000, burnin = 1000
# gbi_null <- gbi_MCMC_custom(associations, thin=1, samples=20000, chains=10, burnin=1000) # Bad
gbi_null_good <- gbi_MCMC_custom(associations, thin=10000, samples=2000, chains=10, burnin=1000) # Good
install.packages("vegan")
library(vegan)
nullmodel(associations, "quasiswap")
null_model <- nullmodel(associations, "quasiswap")
simulate(null_model, 1000)
null_samples <- simulate(null_model, 100)
null_samples[1]
null_samples[[1]]
null_samples
null_samples
null_samples$data
attr(null_samples)
null_samples[, 1]
rowSums(null_samples)
colSums(null_samples)
null_samples["data
null_samples["data"]
null_samples["data"]
null_samples[1:500]
null_samples[1:100]
null_samples$data
